{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impression Generation with FLAN-T5\n",
    "This notebook implements and evaluates a FLAN-T5 model for generating Impression fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "\n",
    "Importing required libraries for the project:\n",
    "\n",
    "### Standard Libraries:\n",
    "- `numpy`: For numerical computations and array operations\n",
    "- `matplotlib.pyplot`: For creating visualizations\n",
    "- `pandas`: For data manipulation and analysis\n",
    "- `torch`: For deep learning operations\n",
    "- `time`: For monitoring execution time\n",
    "- `AzureOpenAI`: For accessing GPT-4 evaluation services\n",
    "\n",
    "### Hugging Face Libraries:\n",
    "- `datasets`: For efficient dataset handling and processing\n",
    "- `transformers`: For working with the FLAN-T5 model and tokenizer\n",
    "- `Trainer`, `TrainingArguments`: For model fine-tuning\n",
    "\n",
    "### Custom Utilities:\n",
    "- `utils_file`: Custom functions for:\n",
    "  - Data preprocessing (`build_finetuning_prompt`, `preprocess_finetuning`)\n",
    "  - Model evaluation (`run_generation_on_dataframe`, `generate_predictions_from_test_dataframe`)\n",
    "  - Performance assessment (`run_equivalence_judgment_flan`, `compute_bertscore`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLaLdxxWxbJ_"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Hugging Face\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Local utils\n",
    "from utils_file import (\n",
    "    build_finetuning_prompt,\n",
    "    preprocess_finetuning,\n",
    "    run_generation_on_dataframe,\n",
    "    generate_predictions_from_test_dataframe,\n",
    "    run_equivalence_judgment_flan,\n",
    "    compute_bertscore\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Loading the preprocessed cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddVM8u2fwq0_"
   },
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv(\"indiana_reports_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize FLAN-T5 Model\n",
    "\n",
    "Loading the pre-trained FLAN-T5 base model components:\n",
    "\n",
    "1. **Model Name**: Using `google/flan-t5-base`, a powerful base model for text generation tasks\n",
    "2. **Tokenizer**: Loading the model's tokenizer for text preprocessing\n",
    "3. **Model**: Loading the model architecture with automatic device placement:\n",
    "   - Uses CUDA GPU if available\n",
    "   - Falls back to CPU if no GPU is present\n",
    "\n",
    "This base model will serve as our starting point for impression generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435,
     "referenced_widgets": [
      "8aa56d7a3d0545e4a9d9bd3b3e3b378d",
      "58a0a534ceb44bcfaf70bac2a6279b2b",
      "377e008a27d849ae87bcd85ab4d18b6f",
      "e825fce2021b442d98ab61fecda0e349",
      "8477d769ea1d45329e10425cece4ea8b",
      "89efb052336741bcbfc8dc4e4633f94c",
      "33f5fe2d05ba4f75aacd23ec213b35b3",
      "c0f7ac1f964149d09acd4d8c97aaf336",
      "6585a0048ef3438da9befdf6cf7208ee",
      "36267706fd6d49ddb50159b0ea0244e0",
      "c1e834dd12064dc9a16f97607a99972f",
      "6553721ffec04a61aeda64b133a9792a",
      "e979b2405f0f47099e91d74244336309",
      "317936e9fe2c479a8f0b039c9e9041d5",
      "ee5ba57f5f75467dbf392b271be33ab4",
      "943750cde56d41c78c4ebc838ebfe9a5",
      "062bc91b69ea442d916ce70e4b9684c2",
      "1d0772cc7e5049999fc37b96dbe2e728",
      "eb76eb7294504f0b8f7dea5ebccdd4d7",
      "b8e1bfebe1a0402c9bcddc6f97c34777",
      "57b54b2faa87475ca2befc67b4d9b6ac",
      "e7d0d40ec3d3402682402b1d6ef0119b",
      "c7f7b3bf713048fa918b112a7ec72c0b",
      "e98cb261fa2242739ec5db040f9485ea",
      "f99d98e26b554b36bfcb305371d47887",
      "f6a9311dbb3e4305805663d0384766a1",
      "67b832970e454d41939dbd4095884cf2",
      "31a1eed7fd9a4fef9207914ebe2eed7b",
      "e7dc2a69148e4794b655908494de2b3f",
      "f3fefe8906da433c8f732e30eb82eea6",
      "adb922a25b3b4a318ee660cdaa4cd323",
      "859dcd4d74ed481f9f55c7f5f39e0284",
      "80293cf4b1b24491ab932eb3694339db",
      "4f830c4d6dd64e96996fae999e45c5a1",
      "5332147ce2fb4e718116ac91de61ef15",
      "34afeaafc9924d45ae3bb70b1cfcbd7a",
      "a57f6b0033234cec8e7490a7c9f55e44",
      "721c3eebbd704315852128816039ff84",
      "af717fca7e164c9f9e2eba0fe6064dc1",
      "03dd7f9db26c4bf8ac3e89cdc1df08c2",
      "43a98cd64ad744b693fb8316a639edb4",
      "5f4d73cf58d7426a8ad532b087267928",
      "c0c503ac517d4bf18fb303d1603bc8dc",
      "07855f0496104f7d86e243b3bb6ab49a",
      "ff2123e3b21e44b4a9170f7606a95095",
      "5af0d0ace88d46818f89237dcef50872",
      "a6c55d96873847898478a76d5e25996e",
      "a74145a372784e0f847b61407cba8e5c",
      "f9f345b2384848d7bb3cd4da12287e5d",
      "9a2330b9220443699d454dca46cbaf52",
      "196ce10c749b4f1d9a889e1f7ec4f257",
      "500a77a2543549ecbbeb2924a4db80f7",
      "ba176260a3c04660a662c65308979063",
      "8d6b754ac0174a95bd0e29fe26816a52",
      "4b233e514eed42c0881839b9bd12ce9a",
      "dca4cd7b70da44c3b0edfe110c119128",
      "dfdaa6715edf4962b7ea4590c36e73e2",
      "7831c74700884071b429cde7ffc36117",
      "f1519706f0304b06a1c7b15086cc8928",
      "f3f0c620bc8f4496b42f894379133ffc",
      "8888cd5664c24e81a4255a97c45a95b3",
      "7913237a1f91444db474ec6845485c95",
      "cc683cf22f164027b43c17dd96e7f06d",
      "9df36e65eb5c40338ed9d64da71ed1f1",
      "43a6adfbfa9744deb5ed860106351752",
      "57960c0e14014ebe89d62843de1cab66",
      "70b9debffd4e4adcb677c94ab1e839d2",
      "c725d9e6887f4c94a223f82874ea3245",
      "11378fc8338d466093fa2274293126a0",
      "f3e4c5c4e6ed44c59afaf64b11e4679a",
      "d741c32b2e394ac49d562e4e07a97993",
      "b76add335e224a8f85b21fd5aa840e93",
      "9f54d32a5c2c47148d04e2a9c2484eed",
      "24574e1bf15444058b556ff2ebdcb36b",
      "f7fb9d2e2269488795ff5f656fd6756a",
      "1c4bfd439a394eca86f34973da2e3c27",
      "54d9bd5459374237b42c5a8cfe9a0c55"
     ]
    },
    "id": "mI_yv13GxpKf",
    "outputId": "fba3125f-6410-46d7-a073-3fcda15b55a5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Baseline Predictions\n",
    "\n",
    "Running initial impression generation with the base FLAN-T5 model:\n",
    "\n",
    "1. Process a sample of 300 reports from the cleaned dataset\n",
    "2. Generate impressions using the base model without fine-tuning\n",
    "3. Save the results to 'generated_impressions_300_flan.csv' for evaluation\n",
    "\n",
    "This establishes our baseline performance before fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQAHeQipxfzR"
   },
   "outputs": [],
   "source": [
    "\n",
    "results_baseline_df = run_generation_on_dataframe(df_cleaned, tokenizer, model, sample_size=300)\n",
    "results_baseline_df.to_csv(\"generated_impressions_300_flan.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Azure OpenAI\n",
    "\n",
    "Setting up the Azure OpenAI client for GPT-4 access. This will be used for evaluating clinical equivalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gU6Mk9At9h9j"
   },
   "outputs": [],
   "source": [
    "# Set up Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_endpoint=\"https://yaniv-mb5gqe3y-eastus2.openai.azure.com/\",\n",
    "    api_key=\"8XhaidlpT0fIOsTT6ynrB5BmtYMP0yoTE2giiovjNDMNYNxBsNpYJQQJ99BEACHYHv6XJ3w3AAAAACOGnVgO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Predictions\n",
    "\n",
    "Using GPT-4 to assess the clinical equivalence between generated and ground truth impressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mB76Mygtyw9Y",
    "outputId": "8015f105-9d0a-40cc-8c96-48f75c7b76a8"
   },
   "outputs": [],
   "source": [
    "\n",
    "results_baseline_df , correct, total, acc = run_equivalence_judgment_flan(\n",
    "    results_baseline_df,\n",
    "    client,\n",
    "    model_name=\"gpt-4o\",\n",
    "    save_path=\"results_with_azure_gpt_judgment_baseline.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Baseline BERTScore\n",
    "\n",
    "Computing BERTScore metrics to evaluate semantic similarity between baseline predictions and reference impressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449,
     "referenced_widgets": [
      "23060a0da54744c0a2b7b4aac6250782",
      "37f7cd432589433883350b73f8686b6e",
      "399a0622e84d4d47bb0633a317fc19a3",
      "308af02903c44a4f8c9dc45445a0d283",
      "b1bd865d38c94325b818c84ea3ed6f80",
      "7cae57905e7c4288a42e589f5e0f7ee7",
      "07e7b49dbcb3454c89663f5040db918b",
      "fe03d4d7d1cf423ca6cf734b1fa499e6",
      "76e8f7c436ba479c9f8a1c3dfa1dcf9b",
      "98415035e61a4492a6545c960f209ff5",
      "6c41eff320994fa89d7b832e7842e56e",
      "3c0bdc3bcd0b42c4807db5e52bff7750",
      "59c9c32f0d1d42929ba1f80ef009611d",
      "74ced96ffacd40a494bc8bd27de1b6db",
      "b83b9c97748347c58b2a2c56f39e58a6",
      "cc5cce79267f4f2e9a095b1d7cdd621b",
      "f19952a9c6b146a8988fabd789043b7d",
      "890478655d59471ebac826913dbfd477",
      "ed91d37533014df4a302f58f35ed6b66",
      "b1ad93ad4846445e8c5b11e1f9fcb977",
      "dc45622908e941e38738bdd5c1ada82e",
      "d35bdfb40f624953a73af3678f702b32",
      "eced6f4d3e954a1f88172e689adc78cd",
      "e042def278de443aba69dbf73e977dd1",
      "ec117c17f79b4654bf2717e1595146e4",
      "c026d6ae1ceb4d3ba68f265469eb2dc0",
      "5b34550f271e47bfb3013c93f7d65a2f",
      "e1954d86be79435ba6583868f806a367",
      "10265431eec945b1b05b6b9f5048c45f",
      "3c175c501f2248af9552f7a71d1a8c1f",
      "1c51daa1ce4d4b059564b82de9adfde2",
      "7999e2475aa84f83ba3ff20d8255ba53",
      "f1f19873ba5049b398caa3b536d7d117",
      "5c16a2358ff246c0ad0d73265fc17b63",
      "8c945f690aea40f199b36fb6c3898263",
      "acde5998a62a41c582af3b587dfb3642",
      "eae6af72e68a4a8282ddec4b2b7fc018",
      "fa85208d289b41eeaf28a4efc1e92625",
      "3a71db206c38462c85ef03d34cb1ddf6",
      "167a47502d1a44b58536f481eca82681",
      "e12d54ffe8294d0fa8be1e240dfe04b5",
      "6a6f74cf9c034d7d9e615efc12e81acb",
      "e2cd80dd96184ace8bb1b2f1a637ae37",
      "239156696e0c4d98a2ffd072f547a539",
      "31bff837f8f8487d94e186faf042380e",
      "30d2fffe1ac341a8888f7846e678d5eb",
      "d7a154f384a848cd90accffba031c0cd",
      "e74a0b8d95164484b534dcb31fd0d064",
      "eb7d0430960b4a32b69c276645e67b7a",
      "f84cfca583484829858960f5e3f641b4",
      "c7f8f5ff9e2c4caca265e8f0656a51e6",
      "94c0150a237c4ade9970e950106e1b99",
      "55b03b6e5d644684ac8a6dfbb45aee8e",
      "61748f6fda2e4d6cb408bada12fa9199",
      "c43b8412605a4cfa8ce7054bc963197c",
      "88832c81af604fbda5fab1ed9e234f9c",
      "c47d5154201d4338b1289ac0009b4c07",
      "41b3d6436d6e4efd9bf2ac8af79f4c6f",
      "e5088769a1414499bdd261fd3f464d44",
      "95cc156f686e4ee7b761e73fbc8f079d",
      "bad466b308bc4301aeae074909f46bd7",
      "3e515ab0ea89430c8d66c6319747b2b6",
      "69b14cc702bb46e0a47e390e9ab919ba",
      "9b9b3926040041c8ab4c51f319f57617",
      "388ed3f0db8f4317a10da3789904b9b5",
      "34ff8b8953044d7281f2073b66e2b599",
      "cb43751e483b43c7bc6f9285cca75265",
      "018376e1b7ec4ce98b4f7bea4d4d51e5",
      "41dc2de7146747bb958dea04b3228708",
      "b44f132facdd47a6bff2d7ea12bace02",
      "0e112a8fae5943de81be2100c8d1aa8b",
      "1266fa8bee0547f7ba680ba18cbb272b",
      "897b42caca1a4159b8c956d2cf1250a9",
      "2e7ec2e0e3964aebb31ebf954498079a",
      "a241fe54b5e041cb8b8cdc478413fd7e",
      "2c8ed4396fc444128ab0e68e51c2077a",
      "a1cae2a88f3c4fa694d6635deb3ea06e",
      "adf1e4f164a84e23b0f833086ae70016",
      "855e89f5c2384257baceebbc29db1faa",
      "3eb752dcb80c4adc8a5744ba05184d33",
      "4358552e2fab40439f5f6a0f3d13b65e",
      "86b90e4c904a4db2a86df12bf74b6df5",
      "6a48c2f14dc14fd0b5f5f9625a98ca72",
      "218b7fc1f6e54ce3bbb51463c9e9ced1",
      "ca3b3d52ef55408c86cb5162270bdaba",
      "ed7145045f4c4e70a71f392f51b1d669",
      "fc384d3a7aa946588fe865cf4ca6a82e",
      "b0a2d26e4b2d4d76ad3aca494d2f3e4e"
     ]
    },
    "id": "6hnAtzuJ6Xrm",
    "outputId": "4ed2c2ae-0058-44b9-e22b-b8763343f8ed"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute BERTScore for baseline model predictions (אם קיים)\n",
    "bert_results_baseline = compute_bertscore(\n",
    "    results_baseline_df,\n",
    "    candidate_col=\"generated_impression\",\n",
    "    reference_col=\"true_impression\",\n",
    "    name_prefix=\"baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune FLAN-T5 Model\n",
    "\n",
    "1. Prepare training data:\n",
    "   - Create input-target pairs\n",
    "   - Convert to HuggingFace Dataset format\n",
    "   - Split into train/validation/test sets (80/10/10)\n",
    "2. Configure training parameters\n",
    "3. Initialize trainer and start fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5ef7a1c617f64680b7569173b2ae0cf9",
      "f9c59f65dc154f4c89e69e0b96d8db14",
      "09a7aa5b0c6b4b7d80ff3092d8f14bcc",
      "2e569eb45d3e48ed80240c187c3aaa3d",
      "0644430f62544acf9d49cab908d72467",
      "271bd434e52646219e7bec8bed5fe934",
      "9a68dcf227b6491e86fd96c367f0d2ba",
      "f453e030c22b4ef8ba87dd794b7e23db",
      "049808c689014afa863eda104737a8b7",
      "d32d6f7a9bb34eb6b748f2f78dc24535",
      "52c369279b524831b17725b24a4348ae",
      "14ad45932b5540cabe73ac2480613e81",
      "8bbde2551fa446bca0391721b46cd21b",
      "af67428f664e4479a077ca60c7dff7fb",
      "5ae4af54e8cb4f3ba22923435865b5da",
      "0ecbce6c1f0e4d7bb4467295f0564df6",
      "166392a4d03e4b38bdc999bec33d0d5e",
      "a82e5cfd4bbe4b739e0a57e1c70e27c4",
      "528c6cd2706a4ba3b2914c3fd2c85a73",
      "73d3a31d98dd48ca9d2c45e3d9607194",
      "357fdc067c8647e48c951474ecf94828",
      "9d26aa75c9d74bf79a6e45dfbe89a274"
     ]
    },
    "id": "TT51H8fZy5LU",
    "outputId": "b98039ec-d539-443c-d067-fc0c594176c0"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preparing the texts for training\n",
    "df_cleaned[\"input_text\"] = df_cleaned.apply(build_finetuning_prompt, axis=1)\n",
    "df_cleaned[\"target_text\"] = df_cleaned[\"impression\"]\n",
    "\n",
    "# Conversion to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df_cleaned[[\"input_text\", \"target_text\"]])\n",
    "\n",
    "# Divided into 80% training, 20% testing\n",
    "split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_eval_dataset = split[\"train\"]\n",
    "test_dataset = split[\"test\"]\n",
    "\n",
    "# Saving the test to disk for future use\n",
    "test_dataset.save_to_disk(\"saved_test_dataset\")\n",
    "print(\"✅ Test set saved to 'saved_test_dataset'\")\n",
    "\n",
    "# Loading Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# Tokenization on training+intermediate evaluation\n",
    "tokenized_dataset = train_eval_dataset.map(lambda x: preprocess_finetuning(x, tokenizer))\n",
    "\n",
    "# Splitting into 90% training, 10% validation\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "\n",
    "\n",
    "# Setting the training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned_impression\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=100,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Loading the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "# Setting the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Starting training\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Fine-tuned Model\n",
    "\n",
    "Saving the fine-tuned model and tokenizer for later use and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AR91mGUI1h-U",
    "outputId": "424c1b6c-689f-49f4-9475-467da97a5285"
   },
   "outputs": [],
   "source": [
    "# Save the model and tokenizer after training\n",
    "trainer.save_model(\"./final_finetuned_model\")\n",
    "tokenizer.save_pretrained(\"./final_finetuned_model\")\n",
    "print(\"✅ Model and tokenizer saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data and Model\n",
    "\n",
    "Loading the saved test dataset and fine-tuned model components for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAMYX3Fe1k9O",
    "outputId": "b6f7bbf1-b6e1-43fb-fada-69c2803eb490"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the saved test set\n",
    "test_dataset = load_from_disk(\"saved_test_dataset\")\n",
    "print(f\"✅ Loaded test dataset with {len(test_dataset)} samples\")\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_path = \"./final_finetuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "print(\"✅ Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Fine-tuned Predictions\n",
    "\n",
    "Generating impressions on the test set using the fine-tuned model and saving results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uL-M9Vc63VNJ",
    "outputId": "c3c8627f-b374-48a7-8b84-f5bc10a5c1d8"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert test dataset to DataFrame\n",
    "test_df = test_dataset.to_pandas()\n",
    "\n",
    "# Generate predictions\n",
    "results_finetuned_df = generate_predictions_from_test_dataframe(test_df, tokenizer, model)\n",
    "\n",
    "# Save to CSV\n",
    "results_finetuned_df.to_csv(\"finetuned_model_test_results.csv\", index=False)\n",
    "print(\"✅ Saved test set predictions to 'finetuned_model_test_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Fine-tuned Predictions\n",
    "\n",
    "Assessing clinical equivalence of fine-tuned model predictions using GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs1pkHxo4bhY",
    "outputId": "cd6d3ae4-b7f6-4dc2-8453-ec6631c26c33"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run equivalence judgment (with the original FLAN-style prompt)\n",
    "results_finetuned_df, correct_ft, total_ft, acc_ft = run_equivalence_judgment_flan(\n",
    "    results_finetuned_df,\n",
    "    client,\n",
    "    model_name=\"gpt-4o\",\n",
    "    save_path=\"results_with_azure_gpt_judgment_finetuned.csv\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Saved equivalence results to 'results_with_azure_gpt_judgment.csv'\")\n",
    "print(f\"✅ Clinical Equivalence Rate: {correct}/{total} = {acc:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Fine-tuned BERTScore\n",
    "\n",
    "Computing BERTScore metrics for the fine-tuned model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222,
     "referenced_widgets": [
      "10e52d3c247448898409ec4d779b21b1",
      "616e1b4934404c568d470b6a20943225",
      "80cb598a270c4fe39f8b80187a2843e5",
      "ce75653376854e7b8d85886d36133218",
      "748a6bbccd6749a295d673a06e9f0cc8",
      "945a4aca50a84eada819b9b39cd4b50b",
      "368cc04abbfd41cb82c3aeb094721ba2",
      "6a9eaf7d1d88437181bfef893ce2ca95",
      "643cf28633534b5bb0504e97f6795bc3",
      "df4647d3c1d147a3a62a245019732f7a",
      "63f0e45cd50d45b1bbdc2b45c9afa21c",
      "7716d6515d874cd99863c8821eec0349",
      "159e21b137914c61b5a06cec8d22ae66",
      "f15ae8b7a186441ab3d2e9a3739eabb9",
      "d7bc102f2ce648978b0be9467efe1d38",
      "64b9d60472df45d88e12ecdc7c2f25ca",
      "1b0725ac32d6491d9e433adee0fd2c2e",
      "c4ce374ced0b49f0a679ea2a7b52add6",
      "e9cdb36b799d406cba0e5d33298e0855",
      "558602e2278645a8b50ba2bff2ad1d56",
      "cdd0094c7d2b40fd904c053e1fc67d20",
      "07bb6f74a6764fa4ac5d022a6bbfa885"
     ]
    },
    "id": "O-4q4KfL6QV6",
    "outputId": "49b06935-f14f-45cf-b0b8-8fb98d2b1bbb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Compute BERTScore for fine-tuned model predictions\n",
    "bert_results_finetuned = compute_bertscore(\n",
    "    results_finetuned_df,\n",
    "    candidate_col=\"generated_impression\",\n",
    "    reference_col=\"true_impression\",\n",
    "    name_prefix=\"finetuned\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Comparison Metrics\n",
    "\n",
    "Collecting evaluation scores from both baseline and fine-tuned models for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "243MRgXVJg_4"
   },
   "outputs": [],
   "source": [
    "\n",
    "llmjudge_baseline = acc\n",
    "llmjudge_finetuned = acc_ft\n",
    "\n",
    "llmjudge_scores = [llmjudge_baseline, llmjudge_finetuned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Performance Comparison\n",
    "\n",
    "Creating a comparative visualization showing:\n",
    "- LLM Judge scores (clinical equivalence %)\n",
    "- BERTScore metrics (F1 scores)\n",
    "for both baseline and fine-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "osgWY2Z36raC",
    "outputId": "a0f500ed-d645-4bea-cb70-5548e86ec874"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Labels\n",
    "labels = ['Baseline', 'Fine-tuned']\n",
    "\n",
    "# LLM Judge scores (percentages)\n",
    "llmjudge_scores = [llmjudge_baseline, llmjudge_finetuned]\n",
    "\n",
    "# BERTScore means and stds\n",
    "bertscore_means = [\n",
    "    bert_results_baseline[\"baseline_mean\"],\n",
    "    bert_results_finetuned[\"finetuned_mean\"]\n",
    "]\n",
    "bertscore_stds = [\n",
    "    bert_results_baseline[\"baseline_std\"],\n",
    "    bert_results_finetuned[\"finetuned_std\"]\n",
    "]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar plot for LLM Judge\n",
    "bar1 = ax1.bar(x - width/2, llmjudge_scores, width, label='LLM Judge (%)', color='tab:blue')\n",
    "ax1.set_ylabel('LLM Judge (%)', color='tab:blue')\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Second y-axis for BERTScore\n",
    "ax2 = ax1.twinx()\n",
    "bar2 = ax2.bar(x + width/2, bertscore_means, width, yerr=bertscore_stds, label='BERTScore F1', color='tab:orange', capsize=5)\n",
    "ax2.set_ylabel('BERTScore F1', color='tab:orange')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('Performance Comparison: Baseline vs Fine-tuned')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
    "\n",
    "# Show grid\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
